

# ğŸ—£ï¸ Parallel Kannada Text-to-Speech (TTS) using Parler-TTS

A high-performance **multicore Kannada Text-to-Speech system** built with the **AI4Bharat Indic Parler-TTS model**.  
This project demonstrates **serial**, **threaded**, and **multiprocessing-based parallel generation** of synthetic speech â€” accelerating TTS workloads using modern CPUs and GPUs.

---

## ğŸš€ Features

- âœ… Kannada TTS using [`ai4bharat/indic-parler-tts-pretrained`](https://huggingface.co/ai4bharat/indic-parler-tts-pretrained)
- âœ… Converts **numbers and Kannada numerals** into spoken Kannada words
- âœ… Three processing modes:
  - **Serial Mode** â€” baseline sequential generation
  - **Threaded Mode** â€” concurrent generation using threads
  - **Multiprocessing Mode** â€” true parallel generation using multiple cores
- âœ… GPU auto-detection and utilization (if available)
- âœ… Adds natural **silence pauses** between sentences
- âœ… Benchmarks **speedup and parallel efficiency**
- âœ… Modular, extensible, and ready for production scaling

---

## ğŸ§  Model Used

| Component | Model |
|------------|--------|
| **TTS Model** | [`ai4bharat/indic-parler-tts-pretrained`](https://huggingface.co/ai4bharat/indic-parler-tts-pretrained) |
| **Voice Description** | â€œA professional female speaker Anu, speaks with clear pronunciation and moderate pacing.â€ |

---

## ğŸ“¦ Requirements

Install the following dependencies before running:

```bash
pip install torch transformers soundfile numpy optimum parler-tts
````

If youâ€™re using GPU acceleration, ensure you have a **CUDA-compatible** version of PyTorch installed.

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ tts_parallel_kannada.py    # Main script
â”œâ”€â”€ README.md                  # Project documentation
â”œâ”€â”€ kannada_tts_serial.wav     # Output (Serial mode)
â”œâ”€â”€ kannada_tts_parallel.wav   # Output (Parallel mode)
â””â”€â”€ requirements.txt           # Python dependencies
```

---

## âš™ï¸ Configuration (from `TTSConfig` class)

| Parameter              | Description                                                         |
| ---------------------- | ------------------------------------------------------------------- |
| `MODEL_NAME`           | Pretrained model name from Hugging Face                             |
| `VOICE_DESCRIPTION`    | Descriptive prompt defining speaker style                           |
| `OUTPUT_FILE_SERIAL`   | Output file name for serial mode                                    |
| `OUTPUT_FILE_PARALLEL` | Output file name for parallel mode                                  |
| `SILENCE_PAUSE`        | Silence duration (in seconds) between sentences                     |
| `MAX_WORKERS`          | Maximum number of parallel processes (auto based on CPU cores)      |
| `BATCH_SIZE`           | Number of sentences processed per thread batch                      |
| `GENERATION_CONFIG`    | Parameters controlling speech generation (temperature, top_k, etc.) |

---

## ğŸ§© How It Works

1. **Text Preprocessing**

   * Replaces digits (both English `0â€“9` and Kannada numerals `à³¦â€“à³¯`) with Kannada word equivalents.
   * Cleans and splits text into manageable sentence chunks.

2. **Model Loading**

   * Loads the `Parler-TTS` model and tokenizers.
   * Uses `BetterTransformer` from the `optimum` library (if installed) for inference optimization.

3. **Processing Modes**

   * **Serial:** Single-process, single-model inference.
   * **Threading:** Multiple threads using one shared model (light parallelism).
   * **Multiprocessing:** Multiple processes with separate model instances (true parallel execution).

4. **Performance Evaluation**

   * Compares total runtime across modes.
   * Calculates **speedup** and **parallel efficiency** metrics.

---

## â–¶ï¸ Usage

### 1ï¸âƒ£ Run Directly (Default CPU or GPU mode)

```bash
python tts_parallel_kannada.py
```

### 2ï¸âƒ£ Specify GPUs (if multiple available)

```bash
CUDA_VISIBLE_DEVICES=0,1 python tts_parallel_kannada.py
```

> The script automatically detects CUDA and distributes workloads across available GPUs or CPU cores.

---

## ğŸ—’ Example Input

```text
à²•à²¨à³à²¨à²¡ à²­à²¾à²·à³† à²­à²¾à²°à²¤à²¦ à²•à²°à³à²¨à²¾à²Ÿà²• à²°à²¾à²œà³à²¯à²¦ à²…à²§à²¿à²•à³ƒà²¤ à²­à²¾à²·à³†à²¯à²¾à²—à²¿à²¦à³†.
à²‡à²¦à³ à²¦à³à²°à²¾à²µà²¿à²¡ à²­à²¾à²·à²¾ à²•à³à²Ÿà³à²‚à²¬à²•à³à²•à³† à²¸à³‡à²°à²¿à²¦à³† à²®à²¤à³à²¤à³ à²¸à³à²®à²¾à²°à³ à³« à²•à³‹à²Ÿà²¿ à²œà²¨à²°à³ à²®à²¾à²¤à²¨à²¾à²¡à³à²µ à²ªà³à²°à²®à³à²– à²­à²¾à²·à³†à²¯à²¾à²—à²¿à²¦à³†.
à²•à²¨à³à²¨à²¡à²µà³ à²…à²¤à³à²¯à²‚à²¤ à²ªà³à²°à²¾à²šà³€à²¨ à²­à²¾à²·à³†à²—à²³à²²à³à²²à²¿à³Šà²‚à²¦à²¾à²—à²¿à²¦à³†, à²‡à²¦à²° à²‡à²¤à²¿à²¹à²¾à²¸ à²¸à³à²®à²¾à²°à³ 2000 à²µà²°à³à²·à²—à²³à²·à³à²Ÿà³ à²¹à²¿à²‚à²¦à²•à³à²•à³† à²¹à³‹à²—à³à²¤à³à²¤à²¦à³†.
à²•à²¨à³à²¨à²¡ à²¸à²¾à²¹à²¿à²¤à³à²¯à²µà³ à²…à²¸à²‚à²–à³à²¯à²¾à²¤ à²•à²µà²¿à²—à²³à³ à²®à²¤à³à²¤à³ à²²à³‡à²–à²•à²°à²¿à²‚à²¦ à²¸à²®à³ƒà²¦à³à²§à²µà²¾à²—à²¿ à²¬à³†à²³à³†à²¦à³ à²¬à²‚à²¦à²¿à²¦à³†.
à²•à³à²µà³†à²‚à²ªà³, à²¬à³‡à²‚à²¦à³à²°à³†, à²•à²¾à²°à²‚à²¤à²°à²‚à²¤à²¹ à²®à²¹à²¾à²¨à³ à²¸à²¾à²¹à²¿à²¤à²¿à²—à²³à³ à²•à²¨à³à²¨à²¡à²•à³à²•à³† à²…à²ªà²¾à²° à²•à³Šà²¡à³à²—à³† à²¨à³€à²¡à²¿à²¦à³à²¦à²¾à²°à³†.
```

The script will automatically convert Kannada numerals like `à³«` â†’ `à²à²¦à³` before generating speech.

---

## ğŸ§¾ Example Output

**Console Output:**

```
ğŸ¯ MULTICORE TTS PARALLEL PROCESSING DEMONSTRATION
ğŸ’» System Information:
   CPU Cores: 12
   GPU Available: True
   GPU Count: 1
   GPU 0: NVIDIA GeForce RTX 3060

ğŸ“Š Dataset: 5 sentences, 412 characters
ğŸ”§ Available workers: 4

ğŸš€ Starting SERIAL processing...
âœ… Serial processing completed in 42.5 seconds

ğŸš€ Starting PARALLEL processing...
âœ… Parallel processing completed in 18.3 seconds

ğŸ“Š PERFORMANCE ANALYSIS
â± Serial Time:    42.50 seconds
â± Parallel Time:  18.30 seconds
ğŸš€ Speedup:        2.32x
ğŸ“ˆ Efficiency:     58.0%
```

---

## ğŸ§® Performance Metrics

| Metric         | Description                           |
| -------------- | ------------------------------------- |
| **Speedup**    | Ratio of serial time to parallel time |
| **Efficiency** | Speedup divided by number of workers  |
| **Workers**    | Number of parallel processes used     |

> Example: 2.3Ã— speedup at 58% efficiency on 4 cores.

---

## ğŸ”¬ Technical Insights

| Mode         | Characteristics                                                 |
| ------------ | --------------------------------------------------------------- |
| **Serial**   | Single model instance, single core, minimal overhead            |
| **Threaded** | Shared model, lightweight concurrency, limited CPU utilization  |
| **Parallel** | Multiple processes, separate models, full multicore utilization |

---

## âš¡ Optimization Opportunities

* ğŸ§© **Model Quantization** for reduced memory footprint
* ğŸš€ **Dynamic Batching** based on sentence length
* ğŸ” **Pipeline Parallelism** to overlap tokenization and inference
* âš™ï¸ **GPU Memory Pooling** for multi-instance acceleration
* ğŸ§  **Caching Description Embeddings** to avoid recomputation

---

## ğŸ“ˆ Example Performance Comparison

| Mode     | Time (s) | Speedup | Efficiency |
| -------- | -------- | ------- | ---------- |
| Serial   | 42.5     | 1.0x    | 100%       |
| Parallel | 18.3     | 2.3x    | 58%        |

---


* [AI4Bharat](https://ai4bharat.org/) â€” for Indic TTS datasets and models
* [Hugging Face](https://huggingface.co/) â€” for Transformers and Parler-TTS
* [Optimum](https://huggingface.co/docs/optimum/index) â€” for transformer acceleration tools

